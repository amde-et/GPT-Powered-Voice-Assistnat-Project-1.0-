# GPT-Powered-Voice-Assistnat-Project-1.0
# Voice Assistant with GPT-4 All Integration

This project implements a voice-controlled assistant that integrates with the GPT-4 All model for generating text-based responses. The assistant listens for a specific wake word and then processes user prompts, generating responses using GPT-4 All. It utilizes the `speech_recognition`, `whisper`, and `pyttsx3` libraries for audio processing, transcription, and speech output.
Fun Fact: It is terminal based for now but it is still handy 
## Features

- Wake word detection: The assistant listens for a specific wake word ("jarvis" by default) to initiate interactions.
- Voice input: Users can speak prompts, which are transcribed and used as input to the GPT-4 All model.
- Text output: Responses generated by the GPT-4 All model are converted to speech output using the `pyttsx3` library.
- Efficiency: The code has been optimized to minimize file I/O, load models only once, and improve overall efficiency.

## Prerequisites

- Python 3.x
- Install required packages: `pip install speech_recognition whisper pyttsx3 gpt4all`

## Usage

1. Clone this repository:
   ```bash

2. Install the required packages:
3. Download the GPT-4 All model and place it in the appropriate location (update the path in the code).
4. Speak the wake word ("Selam" by default) to activate the assistant. Once activated, speak prompts to get responses from GPT-4 All.
****    Customization******

You can customize the wake word by changing the wake_word variable in the code.
Adjust the paths to the GPT-4 All model and other required files as necessary.
**Acknowledgments**
Thank you to my friend AbdulBari(AddisCoder'23)
This project was inspired by the idea of creating a voice-controlled assistant using modern AI models.
We thank the creators of the speech_recognition, whisper, and pyttsx3 libraries for providing tools that make this project possible.
Special thanks to OpenAI for their GPT-4 All model.
